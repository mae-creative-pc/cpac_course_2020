{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex. II - Deep Interactive Evolution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyaKrPvJxmVw"
      },
      "source": [
        "#Deep Interactive Evolution\n",
        "\n",
        "This colab is an unofficial implementation of the \"Deep Interactive Evolution\" Paper\n",
        "\n",
        "![testo del link](https://storage.googleapis.com/groundai-web-prod/media%2Fusers%2Fuser_76290%2Fproject_252337%2Fimages%2Fx1.png) \n",
        "\n",
        "We'll consider two models of which we are going to \"evolve\" the embeddings\n",
        "\n",
        "* CelebA Progressive GAN Model\n",
        "* MusicVAE\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K8rqMA7MwPc"
      },
      "source": [
        "import imageio\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI0M_apz0NZA"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "9o54d9P500y5"
      },
      "source": [
        "#@title Imports\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "import glob\n",
        "\n",
        "BASE_DIR = \"gs://download.magenta.tensorflow.org/models/music_vae/colab2\"\n",
        "\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -q pyfluidsynth\n",
        "!pip install -qU magenta\n",
        "\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib.\n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "\n",
        "print('Importing libraries and defining some helper functions...')\n",
        "from google.colab import files\n",
        "import magenta.music as mm\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "import numpy as np\n",
        "#import tensorflow.compat.v1 as tf\n",
        "#tf.disable_v2_behavior()\n",
        "import tensorflow as tf\n",
        "\n",
        "# Necessary until pyfluidsynth is updated (>1.2.5).\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)\n",
        "\n",
        "def play(note_sequence):\n",
        "  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n",
        "\n",
        "def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n",
        "                assert_same_length=True, temperature=0.5,\n",
        "                individual_duration=4.0):\n",
        "  \"\"\"Interpolates between a start and end sequence.\"\"\"\n",
        "  note_sequences = model.interpolate(\n",
        "      start_seq, end_seq,num_steps=num_steps, length=max_length,\n",
        "      temperature=temperature,\n",
        "      assert_same_length=assert_same_length)\n",
        "\n",
        "  print('Start Seq Reconstruction')\n",
        "  play(note_sequences[0])\n",
        "  print('End Seq Reconstruction')\n",
        "  play(note_sequences[-1])\n",
        "  print('Mean Sequence')\n",
        "  play(note_sequences[num_steps // 2])\n",
        "  print('Start -> End Interpolation')\n",
        "  interp_seq = mm.sequences_lib.concatenate_sequences(\n",
        "      note_sequences, [individual_duration] * len(note_sequences))\n",
        "  play(interp_seq)\n",
        "  mm.plot_sequence(interp_seq)\n",
        "  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n",
        "\n",
        "def download(note_sequence, filename):\n",
        "  mm.sequence_proto_to_midi_file(note_sequence, filename)\n",
        "  files.download(filename)\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzikYURz88Xo"
      },
      "source": [
        "# Part I CelebA Progressive GAN Model\n",
        "\n",
        "[Progressive GAN](https://arxiv.org/abs/1710.10196) model that maps N-dimensional latent vectors to RGB images, which in this case correspond to photos of celebrities\n",
        "\n",
        "We'll use a [TensorFlow Hub](https://www.tensorflow.org/hub) pre-trained model to take advantage of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur14Hj-COw_O"
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "\n",
        "from tensorflow_docs.vis import embed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ0DKi8CGkrP"
      },
      "source": [
        "# Code to plot images and animations...\n",
        "def display_image(image):\n",
        "  image = tf.constant(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "  return PIL.Image.fromarray(image.numpy())\n",
        "\n",
        "\n",
        "def animate(images):\n",
        "  images = np.array(images)\n",
        "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "  imageio.mimsave('./animation.gif', converted_images)\n",
        "  return embed.embed_file('./animation.gif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_FO6xw51BHf"
      },
      "source": [
        "Load the TensorFlow Hub model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmVaLueZFcWq"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "progan = hub.load(\"https://tfhub.dev/google/progan-128/1\").signatures['default']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LFhWB6rFk82"
      },
      "source": [
        "The model takes as input a vector of latent_dim=512 elements extracted from a normal distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n3PtygTFe_v"
      },
      "source": [
        "latent_dim = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi3D6312Ismd"
      },
      "source": [
        "try to run the following cell several times and see how the results change, each time you generate a different latent vector, you obtain a different image as output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLMhKxicGY4y"
      },
      "source": [
        "z = tf.random.normal([latent_dim])\n",
        "output_img = progan(z)['default']\n",
        "display_image(output_img[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG86hzPiLBr7"
      },
      "source": [
        "Latent vectors (or embeddings) correspond to image representations in multidimensional spaces we can interpolate between them and \"merge\" different images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm_GR1KiLmwK"
      },
      "source": [
        "def interpolate_hypersphere(v1, v2, num_steps):\n",
        "  v1_norm = tf.norm(v1)\n",
        "  v2_norm = tf.norm(v2)\n",
        "  v2_normalized = v2 * (v1_norm / v2_norm)\n",
        "\n",
        "  vectors = []\n",
        "  for step in range(num_steps):\n",
        "    interpolated = v1 + (v2_normalized - v1) * step / (num_steps - 1)\n",
        "    interpolated_norm = tf.norm(interpolated)\n",
        "    interpolated_normalized = interpolated * (v1_norm / interpolated_norm)\n",
        "    vectors.append(interpolated_normalized)\n",
        "  return tf.stack(vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNlPWTbhLxvz"
      },
      "source": [
        "Let us consider two latent vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWg799Y3L0Zm"
      },
      "source": [
        "z1 = tf.random.normal([latent_dim])\n",
        "output_img = progan(z1)['default']\n",
        "display_image(output_img[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIPLekMaL3PY"
      },
      "source": [
        "z2 = tf.random.normal([latent_dim])\n",
        "output_img = progan(z2)['default']\n",
        "display_image(output_img[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtfDErDiL7z4"
      },
      "source": [
        "They correspond to two diffewrent images, we can interpolate btw the two vectors to change one image in the other one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A6-WttkMCIj"
      },
      "source": [
        "# Creates a tensor with 50 steps of interpolation between v1 and v2.\n",
        "interpolated_vectors = interpolate_hypersphere(z1, z2, 50)\n",
        "\n",
        "# Uses module to generate images from the latent space.\n",
        "interpolated_images = progan(interpolated_vectors)['default']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7I9gieUMPQo"
      },
      "source": [
        "animate(interpolated_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4mSPnALQBD3"
      },
      "source": [
        "### Deep Interactive Evolution with CelebA\n",
        "\n",
        "Now we start applying the Deep Interactive evolution model to celebA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNsucjWVSQ4X"
      },
      "source": [
        "### Uniform Crossover: FILL THE CODE\n",
        "\n",
        "Two parents are randomly selected and an offspring is generated by choosing from two parents with equal probablity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6Y8CINRXQ5d"
      },
      "source": [
        "# Generate a population of vectors of size pop_len X latent_dim\n",
        "pop_len = 10\n",
        "population = #... FILL THE CODE\n",
        "\n",
        "# Select two parents randomly from the population: FILL THE CODE\n",
        "# HINT use np.random.randint\n",
        "# population is a n_pop X latent_dim matrix\n",
        "z1 =  #... FILL THE CODE\n",
        "z2 =  #... FILL THE CODE\n",
        "\n",
        "# Generate a binary mask using a binomial distribution with params n=1 p=0.5\n",
        "# HINT: use np.random.binomial\n",
        "mask =  #... FILL THE CODE\n",
        "\n",
        "# Compute uniform crossover between the two parents: FILL THE CODE\n",
        "# Use the computed binary mask to crossover the two vectords\n",
        "crossover =  #... FILL THE CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqYtp5DsYiWr"
      },
      "source": [
        "plot the result of uniform crossover"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo1eNYK1ST6C"
      },
      "source": [
        "plt.subplot(131)\n",
        "plt.imshow(progan(z1)['default'][0],aspect='auto'),plt.axis('off')\n",
        "plt.title('Parent I')\n",
        "plt.subplot(132)\n",
        "plt.imshow(progan(z2)['default'][0],aspect='auto'),plt.axis('off')\n",
        "plt.title('Parent II')\n",
        "plt.subplot(133)\n",
        "plt.imshow(progan(crossover)['default'][0],aspect='auto'),plt.axis('off')\n",
        "plt.title(' Uniform Crossover')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKmqSghRaGwK"
      },
      "source": [
        "Now wrap up the Crossover process since we will be using it into the Deep Interactive Evolution algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwt9LiohaQsD"
      },
      "source": [
        "def uniform_crossover(population):\n",
        "  #... FILL THE CODE (copy it from what you did before)\n",
        "\n",
        "  return crossover"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQZlmEtGZSlo"
      },
      "source": [
        "### Mutate: FILL THE CODE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Now we implement the process where a vector is randomly mutated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34rqApf8ZRtM"
      },
      "source": [
        "\n",
        "p = 0.5 # probability of mutation happening\n",
        "mutate_var = 0.3 # variance of the normal distribution with with the embeddings\n",
        "                  # are modified\n",
        "\n",
        "def mutate(individual, mutate_var):\n",
        "  # individual is a latent vector\n",
        "  # Binomial distribution probability we want as output either zero or one with a \n",
        "  # 0.5 probability\n",
        "  # FILL THE CODE: hint np.random.binomial\n",
        "  mutate_cond =  #... FILL THE CODE\n",
        "\n",
        "  # mutation noise\n",
        "  # HINT np.random.randn\n",
        "  noise =  #... FILL THE CODE\n",
        "\n",
        "  # Mutated offspring, N.B. mutation happens depending on  mutate_cond\n",
        "  mutated_offspring =  #... FILL THE CODE\n",
        "\n",
        "  return mutated_offspring"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug40XocueFj6"
      },
      "source": [
        "Generate a latent vector and its mutated offspring and look at the obtained images. Try different values for `mutate_rate` to see how the mutation changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H8LWkTGegld"
      },
      "source": [
        "z1 = tf.random.normal([latent_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU-_vFd4dPOb"
      },
      "source": [
        "# apply mutation\n",
        "mutated_z1 = mutate(z1,0.5)\n",
        "\n",
        "# show results\n",
        "plt.subplot(121)\n",
        "plt.imshow(progan(z1)['default'][0],aspect='auto'),plt.axis('off')\n",
        "plt.title('Individual')\n",
        "plt.subplot(122)\n",
        "plt.imshow(progan(mutated_z1)['default'][0],aspect='auto'),plt.axis('off')\n",
        "plt.title('Mutation')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9c_2bSYer40"
      },
      "source": [
        "### Evolve: FILL THE CODE\n",
        "\n",
        "Now we finally define the function that will enable the evolution of our population"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cGlx0C4p08L"
      },
      "source": [
        "# number of foreign individuals (chromosomes) introduced at each iteration\n",
        "foreign = 2 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m94LDfXme23l"
      },
      "source": [
        "def evolve(z, indices, mutate_var, shuffle=True):\n",
        "  \"\"\"\n",
        "  z: latent vectors corresponding to the members of the populations\n",
        "  indices: indices of the selected latent vectors\n",
        "  mutate_var: mutation rate\n",
        "  shuffle: change presented vectors order\n",
        "  \"\"\"\n",
        "\n",
        "  # Select the vectors that we want to preserve from the population: FILL THE CODE\n",
        "  selections =  #... FILL THE CODE\n",
        "  \n",
        "  # Difference between total number of desired chromosomes and the selected ones\n",
        "  diff = n_pop-len(selections)\n",
        "  x = np.max([0, diff])\n",
        "\n",
        "  # Perform uniform crossover and mutation: FILL THE CODE \n",
        "  # HINT: Perform crossover, then mutation \n",
        "  # HINT: output matrix must be a np.array of size x-foreign X latent_dim\n",
        "  cross = np.array([ #... FILL THE CODE ]).squeeze(axis=1)\n",
        " \n",
        "  # Introduce new chromosomes/individuals!\n",
        "  x = np.min((foreign,diff))\n",
        "  new = np.random.randn(x,latent_dim) # new individual \n",
        "\n",
        "  # Apply mutation to selections\n",
        "  selections = np.array([ #... FILL THE CODE]).squeeze(axis=1)\n",
        "\n",
        "\n",
        "  # Stack together the population vectors\n",
        "  z = np.vstack((selections, cross, new))\n",
        "\n",
        "  # if not shuffle, the first n(selected) samples are mutated selected samples, \n",
        "    # the last n(foreign) samples are foreign samples, and all samples inbetween are crossovers\n",
        "  if shuffle:\n",
        "      np.random.shuffle(z) \n",
        "  return z\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwz7X_VksWmA"
      },
      "source": [
        "# Finally perform evolution!\n",
        "\n",
        "First generate a population of latent vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oqj8bLltXq1"
      },
      "source": [
        "z = tf.random.normal([n_pop,latent_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw2r0Y8lujmY"
      },
      "source": [
        "Run the next two cells continuously to simulate the interactive evolution process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INuSoJuJtC9x"
      },
      "source": [
        "print('Start Img Generation')\n",
        "for i in range(n_pop):\n",
        "  imgs = progan(z[i])['default'][0]\n",
        "  plt.subplot(2,int(n_pop/2),i+1)\n",
        "  plt.imshow(imgs,aspect='auto')\n",
        "  plt.title(str(i))\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXQhRtMYtqxp"
      },
      "source": [
        "list_selected = [8, 0] # insert the indices of the samples you'd like to keep\n",
        "\n",
        "z = z.numpy() # tf stuff\n",
        "z = evolve(z.numpy(), list_selected, mutate_var=0.2, shuffle=True)\n",
        "z = tf.convert_to_tensor(tf.cast(z,dtype=tf.float32)) # tf stuff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9wm9UMHDIE9"
      },
      "source": [
        "# Part II MusicVAE\n",
        "\n",
        "We now repeat the same process only this time using MusicVae"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhnNkG4S02ZD"
      },
      "source": [
        "#title Load the pre-trained model.\n",
        "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
        "model = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path=BASE_DIR + '/checkpoints/mel_2bar_big.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqIwWkrIxk3D"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKWw0GMJHCYg"
      },
      "source": [
        "z = np.random.randn(n_pop, latent_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhx_BVo7HODO"
      },
      "source": [
        "note_sequences = model.decode(\n",
        "      length=32,\n",
        "      z=z,\n",
        "      temperature=0.8)\n",
        "\n",
        "print('Start Seq Reconstruction')\n",
        "for i in range(n_pop):\n",
        "  print(str(i)) \n",
        "  play(note_sequences[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqnZPIpLHZRt"
      },
      "source": [
        "list_selected = [8, 0] # insert the indices of the samples you'd like to keep\n",
        "z = evolve(z, list_selected, mutate_rate=0.2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}